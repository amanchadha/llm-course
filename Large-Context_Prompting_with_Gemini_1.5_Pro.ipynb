{"cells":[{"attachments":{},"cell_type":"markdown","id":"80302e80-b8e3-41e2-b2dd-066a08b85b90","metadata":{"execution":{"iopub.execute_input":"2024-04-15T06:57:34.001708Z","iopub.status.busy":"2024-04-15T06:57:34.001462Z","iopub.status.idle":"2024-04-15T06:57:34.006423Z","shell.execute_reply":"2024-04-15T06:57:34.005563Z","shell.execute_reply.started":"2024-04-15T06:57:34.001692Z"},"language":"python"},"source":"<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(209, 153, 255, 0.25); padding: 5px;\">\n    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/vector-circle.png\" />\n    </div>\n    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Large-Context Prompting with Gemini 1.5 Pro\n        </h1>\n    </div>\n</div>"},{"cell_type":"code","execution_count":62,"id":"0df6f320-852d-4e3e-a70d-3b6f944dbfac","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:09:39.792674Z","iopub.status.busy":"2024-05-19T00:09:39.792430Z","iopub.status.idle":"2024-05-19T00:09:39.795477Z","shell.execute_reply":"2024-05-19T00:09:39.794890Z","shell.execute_reply.started":"2024-05-19T00:09:39.792658Z"},"language":"python","trusted":true},"outputs":[],"source":"import os\nos.environ[\"GEMINI_API_KEY\"]= 'Key'"},{"attachments":{},"cell_type":"markdown","id":"b572f316-98da-4368-ac53-cc6b6c86865c","metadata":{"language":"python"},"source":"## Setup\nLet's first download the libraries necessary."},{"cell_type":"code","execution_count":63,"id":"e0542521-8c3b-44f7-a067-4df989358651","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:09:39.798602Z","iopub.status.busy":"2024-05-19T00:09:39.798382Z","iopub.status.idle":"2024-05-19T00:09:42.202479Z","shell.execute_reply":"2024-05-19T00:09:42.201846Z","shell.execute_reply.started":"2024-05-19T00:09:39.798589Z"},"language":"python","scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\nNote: you may need to restart the kernel to use updated packages.\n"}],"source":"pip install PyPDF2"},{"attachments":{},"cell_type":"markdown","id":"772de2a0-0efd-4b29-bd63-37ca4b162765","metadata":{"execution":{"iopub.execute_input":"2024-04-15T07:13:49.580830Z","iopub.status.busy":"2024-04-15T07:13:49.580554Z","iopub.status.idle":"2024-04-15T07:13:49.584557Z","shell.execute_reply":"2024-04-15T07:13:49.583840Z","shell.execute_reply.started":"2024-04-15T07:13:49.580812Z"},"language":"python","scrolled":true},"source":"## Text input into Gemini\nWe'll be prompting Gemini with multiple modalities. Let's start with text:"},{"cell_type":"code","execution_count":64,"id":"ebb34ac7-4c68-4b93-8b9a-67f1ee52b781","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:09:42.204291Z","iopub.status.busy":"2024-05-19T00:09:42.204076Z","iopub.status.idle":"2024-05-19T00:09:42.240842Z","shell.execute_reply":"2024-05-19T00:09:42.240406Z","shell.execute_reply.started":"2024-05-19T00:09:42.204268Z"},"language":"python","trusted":true},"outputs":[],"source":"import requests\nfrom io import BytesIO\nfrom PyPDF2 import PdfReader"},{"attachments":{},"cell_type":"markdown","id":"d17892bf-3263-4f58-8924-a5db82b88971","metadata":{"language":"python"},"source":"# Function to load content from a PDF"},{"cell_type":"code","execution_count":65,"id":"3c915ecf-3f99-4a1c-9ca5-e68ff0910c49","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:09:42.241889Z","iopub.status.busy":"2024-05-19T00:09:42.241560Z","iopub.status.idle":"2024-05-19T00:09:42.245159Z","shell.execute_reply":"2024-05-19T00:09:42.244670Z","shell.execute_reply.started":"2024-05-19T00:09:42.241868Z"},"language":"python","trusted":true},"outputs":[],"source":"# def load_pdf_from_url(url):\n#     \"\"\"\n#     Reads the text content from a PDF file at a specified URL and returns it as a single string.\n# \n#     Parameters:\n#     - url (str): The URL to the PDF file.\n# \n#     Returns:\n#     - str: The concatenated text content of all pages in the PDF.\n# \n#     Raises:\n#     - requests.exceptions.RequestException: If the request to the URL fails.\n#     - PyPDF2.utils.PdfReadError: If the PDF file is encrypted or malformed.\n# \n#     Example:\n#     >>> pdf_text = load_pdf_from_url(\"https://example.com/example.pdf\")\n#     >>> print(pdf_text)\n#     \"This is the text content extracted from the PDF file.\"\n#     \"\"\"\n#     # Fetch the PDF content from the URL\n#     response = requests.get(url)\n#     response.raise_for_status()  # Ensure that the request was successful\n# \n#     # Create a file-like object from the downloaded PDF content\n#     pdf_file = BytesIO(response.content)\n# \n#     # Read the PDF using PyPDF2\n#     reader = PdfReader(pdf_file)\n#     text = \"\"\n#     for page in reader.pages:\n#         text += page.extract_text() or \"\"\n# \n#     return text\n# \n# # Example usage\n# link = \"https://github.com/saurabhgssingh/RAG/blob/f1aefa5e969a559e88d9a4f03a12d1504e5580c4/state_of_the_union.pdf\"\n# pdf_url = (link.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob/\", \"/\"))\n# #print(pdf_url)\n# pdf_text = load_pdf_from_url(pdf_url)\n# print(pdf_text)\n"},{"attachments":{},"cell_type":"markdown","id":"4ab62433-2dd0-4eab-a2bd-d9b8b83384c9","metadata":{"execution":{"iopub.execute_input":"2024-05-18T23:53:53.634990Z","iopub.status.busy":"2024-05-18T23:53:53.634743Z","iopub.status.idle":"2024-05-18T23:53:53.637692Z","shell.execute_reply":"2024-05-18T23:53:53.637105Z","shell.execute_reply.started":"2024-05-18T23:53:53.634974Z"},"language":"python"},"source":"# Few-shot Learning with 10 SST2 examples"},{"cell_type":"code","execution_count":66,"id":"c86cb6f8-7f5d-4649-889d-032b47268f46","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:09:42.246146Z","iopub.status.busy":"2024-05-19T00:09:42.245859Z","iopub.status.idle":"2024-05-19T00:09:42.253503Z","shell.execute_reply":"2024-05-19T00:09:42.253043Z","shell.execute_reply.started":"2024-05-19T00:09:42.246128Z"},"language":"python","trusted":true},"outputs":[],"source":"# A few-shot learning prompt for sentiment analysis, modeled after the SST-2 (Stanford Sentiment Treebank 2) dataset structure. \n# The format consists of the sentence followed by its sentiment label.\n\nprompt = '''Task: Sentiment Analysis\nGiven a sentence, classify its sentiment as either positive or negative.\n\nExamples:\n\nExample 1:\nSentence: \"The movie was a fantastic experience!\"\nSentiment: Positive\n\nExample 2:\nSentence: \"I really enjoyed the storyline and the characters.\"\nSentiment: Positive\n\nExample 3:\nSentence: \"This was a waste of my time.\"\nSentiment: Negative\n\nExample 4:\nSentence: \"I wouldn't recommend this to anyone.\"\nSentiment: Negative\n\nExample 5:\nSentence: \"The plot was intriguing and kept me engaged.\"\nSentiment: Positive\n\nExample 6:\nSentence: \"The acting was terrible and the script was even worse.\"\nSentiment: Negative\n\nExample 7:\nSentence: \"An absolute masterpiece that I will remember for a long time.\"\nSentiment: Positive\n\nExample 8:\nSentence: \"I was bored throughout the entire film.\"\nSentiment: Negative\n\nExample 9:\nSentence: \"The special effects were stunning and added a lot to the movie.\"\nSentiment: Positive\n\nExample 10:\nSentence: \"It had potential but ended up being disappointing.\"\nSentiment: Negative\n\nNow, analyze the sentiment of the following sentences:\n\nSentence: \"The visuals were impressive, but the story was lackluster.\"\nSentiment: \n\nSentence: \"A brilliant piece of cinema that left me speechless.\"\nSentiment: \n\nSentence: \"The film was too long and uninteresting.\"\nSentiment: \n\nSentence: \"An engaging and well-crafted narrative.\"\nSentiment: \n'''"},{"attachments":{},"cell_type":"markdown","id":"f6520101-8499-4b7d-9dd1-ce586871e46a","metadata":{"language":"python"},"source":"# Generating 10K samples for Gemini's Large-Context Prompt"},{"cell_type":"code","execution_count":73,"id":"a66f406d-bd11-41eb-a8e9-a397803f2bda","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:12:23.993858Z","iopub.status.busy":"2024-05-19T00:12:23.993547Z","iopub.status.idle":"2024-05-19T00:12:24.008205Z","shell.execute_reply":"2024-05-19T00:12:24.007684Z","shell.execute_reply.started":"2024-05-19T00:12:23.993838Z"},"language":"python","trusted":true},"outputs":[],"source":"# Code to generate the samples dynamically\n# Refer Many-Shot In-Context Learning (https://arxiv.org/abs/2404.11018)\n# Paper review: https://aman.ai/papers/#many-shot-in-context-learning\n\nimport random\n\n# Define a list of 100 positive and negative sentiments\npositive_sentiments = [\n    \"The movie was a fantastic experience!\",\n    \"I really enjoyed the storyline and the characters.\",\n    \"The plot was intriguing and kept me engaged.\",\n    \"An absolute masterpiece that I will remember for a long time.\",\n    \"The special effects were stunning and added a lot to the movie.\",\n    \"A brilliant piece of cinema that left me speechless.\",\n    \"An engaging and well-crafted narrative.\",\n    \"A thoroughly enjoyable and entertaining movie.\",\n    \"The direction and performances were top-notch.\",\n    \"A must-watch for any movie lover.\",\n    \"The film was a visual treat with great performances.\",\n    \"A heartwarming story that resonated with me.\",\n    \"Excellent cinematography and a captivating plot.\",\n    \"A great blend of action, drama, and humor.\",\n    \"The soundtrack added so much to the experience.\",\n    \"A moving and beautifully told story.\",\n    \"The actors delivered outstanding performances.\",\n    \"The film exceeded all my expectations.\",\n    \"A beautifully crafted piece of cinema.\",\n    \"A gripping and intense film from start to finish.\",\n    \"A wonderful depiction of the story with great depth.\",\n    \"A perfect mix of suspense and emotion.\",\n    \"A refreshing take on a well-known genre.\",\n    \"The film's pacing was perfect, keeping me engaged.\",\n    \"A delightful movie with a lot of heart.\",\n    \"The plot twists were unexpected and thrilling.\",\n    \"The movie was both entertaining and thought-provoking.\",\n    \"A visually stunning and emotionally rich film.\",\n    \"An inspiring and uplifting story.\",\n    \"The character development was exceptional.\",\n    \"A beautiful portrayal of human emotions.\",\n    \"A film that keeps you on the edge of your seat.\",\n    \"A masterful performance by the lead actor.\",\n    \"A heartfelt and sincere movie experience.\",\n    \"The film had a perfect blend of humor and drama.\",\n    \"A touching story that left a lasting impression.\",\n    \"A brilliant adaptation of the original story.\",\n    \"A film that I would gladly watch again.\",\n    \"An epic tale told with great skill and passion.\",\n    \"The dialogue was sharp and witty.\",\n    \"A magical journey from start to finish.\",\n    \"The film had a powerful and meaningful message.\",\n    \"A must-see for fans of the genre.\",\n    \"The director's vision was executed perfectly.\",\n    \"A poignant and emotional story.\",\n    \"The film's realism was both shocking and beautiful.\",\n    \"A deeply moving and thought-provoking film.\",\n    \"An incredible journey that I enjoyed thoroughly.\",\n    \"The cinematography was breathtaking.\",\n    \"A compelling narrative that kept me hooked.\",\n    \"An absolute delight for the senses.\",\n    \"The movie's themes were explored beautifully.\",\n    \"A stunning achievement in filmmaking.\",\n    \"A film that touched my heart.\",\n    \"A timeless story told in a unique way.\",\n    \"The chemistry between the leads was fantastic.\",\n    \"A film that is both entertaining and profound.\",\n    \"A remarkable and unforgettable movie.\",\n    \"The visual effects were top-notch.\",\n    \"A deeply engaging and rewarding experience.\",\n    \"An outstanding piece of storytelling.\",\n    \"A film that offers both thrills and heart.\",\n    \"A touching and beautifully crafted movie.\",\n    \"The movie's message was powerful and clear.\",\n    \"An excellent example of its genre.\",\n    \"A captivating and emotional rollercoaster.\",\n    \"The film was executed with great precision.\",\n    \"An unforgettable and moving film.\",\n    \"A powerful story told with great sensitivity.\",\n    \"A film that is both smart and entertaining.\",\n    \"The movie had a lot of heart and soul.\",\n    \"A masterclass in acting and direction.\",\n    \"A beautifully written and directed film.\",\n    \"The film's emotional impact was profound.\",\n    \"A perfect film in every way.\",\n    \"The movie was a beautiful experience.\",\n    \"An inspiring tale of resilience and hope.\",\n    \"A film that was both entertaining and insightful.\",\n    \"A rich and textured story.\",\n    \"An unforgettable cinematic experience.\",\n    \"The film's attention to detail was remarkable.\",\n    \"A touching and heartfelt story.\",\n    \"A film that left me with a smile.\",\n    \"The movie was a joy to watch.\",\n    \"An impressive and captivating film.\",\n    \"A story that was both unique and universal.\",\n    \"A film that will stay with me for a long time.\",\n    \"A powerful and emotional journey.\",\n    \"The movie was a perfect blend of art and entertainment.\",\n    \"A thoroughly enjoyable film experience.\",\n    \"A movie that was both engaging and thought-provoking.\",\n    \"An expertly crafted film.\",\n    \"A deeply affecting and beautifully told story.\",\n    \"A film that was as entertaining as it was moving.\",\n    \"An excellent film that I highly recommend.\",\n    \"A beautiful and inspiring story.\"\n]\n\nnegative_sentiments = [\n    \"This was a waste of my time.\",\n    \"I wouldn't recommend this to anyone.\",\n    \"The acting was terrible and the script was even worse.\",\n    \"I was bored throughout the entire film.\",\n    \"It had potential but ended up being disappointing.\",\n    \"The film was too long and uninteresting.\",\n    \"The story was predictable and unoriginal.\",\n    \"I found the movie to be extremely dull.\",\n    \"The characters were poorly developed.\",\n    \"An overhyped movie that didn't live up to expectations.\",\n    \"The plot was a mess and hard to follow.\",\n    \"The special effects couldn't save the bad script.\",\n    \"The movie lacked any real substance.\",\n    \"A cliched and uninspired film.\",\n    \"The performances were wooden and unconvincing.\",\n    \"The film felt disjointed and poorly paced.\",\n    \"A forgettable and bland movie.\",\n    \"The dialogue was cringe-worthy.\",\n    \"A poorly executed film with little to offer.\",\n    \"I regret watching this movie.\",\n    \"The direction was amateurish.\",\n    \"The film was a complete letdown.\",\n    \"A boring and uneventful movie.\",\n    \"The movie failed to keep my interest.\",\n    \"A lackluster and uninspired film.\",\n    \"The story was weak and unengaging.\",\n    \"The film's pacing was all over the place.\",\n    \"A dull and lifeless movie.\",\n    \"The characters were one-dimensional and boring.\",\n    \"The film was poorly written and directed.\",\n    \"A tedious and monotonous movie.\",\n    \"The film's plot was full of holes.\",\n    \"A movie that was a chore to sit through.\",\n    \"The acting was subpar and unconvincing.\",\n    \"The film lacked any real excitement.\",\n    \"A movie that fell flat in every way.\",\n    \"The ending was unsatisfying and abrupt.\",\n    \"The film was poorly edited.\",\n    \"A movie that tried too hard and failed.\",\n    \"The plot was convoluted and confusing.\",\n    \"A disappointing and forgettable film.\",\n    \"The movie was overly long and boring.\",\n    \"A film that lacked any real emotion.\",\n    \"The performances were lackluster.\",\n    \"A movie that was all style and no substance.\",\n    \"The film was a major disappointment.\",\n    \"A poorly acted and directed movie.\",\n    \"The story was unoriginal and boring.\",\n    \"A film that was difficult to get through.\",\n    \"The movie had no real plot.\",\n    \"A film that was completely uninteresting.\",\n    \"The direction was sloppy.\",\n    \"The movie was a letdown in every way.\",\n    \"The film lacked any real tension.\",\n    \"A boring and uninspired movie.\",\n    \"The movie was a disaster from start to finish.\",\n    \"The plot was dull and unengaging.\",\n    \"A film that was hard to sit through.\",\n    \"The acting was terrible and unconvincing.\",\n    \"The film was a total waste of time.\",\n    \"The movie was boring and lifeless.\",\n    \"A film that failed to deliver.\",\n    \"The plot was weak and unoriginal.\",\n    \"A movie that was difficult to watch.\",\n    \"The film had no redeeming qualities.\",\n    \"A dull and uninspired movie.\",\n    \"The movie was a mess.\",\n    \"The film was poorly made.\",\n    \"A boring and forgettable movie.\",\n    \"The acting was bad and the story was worse.\",\n    \"A film that was a complete waste of time.\",\n    \"The movie was uninteresting and dull.\",\n    \"A poorly executed and boring film.\",\n    \"The story was predictable and boring.\",\n    \"A film that was lacking in every way.\",\n    \"The movie was a complete failure.\",\n    \"The film was a major disappointment.\",\n    \"A movie that was boring and unoriginal.\",\n    \"The plot was uninteresting and dull.\",\n    \"A film that was a waste of time.\",\n    \"The movie was poorly directed and acted.\",\n    \"A boring and uninspired film.\",\n    \"The movie was a complete letdown.\",\n    \"The film was a chore to watch.\",\n    \"A movie that was devoid of any real emotion.\",\n    \"The film was a total bore.\",\n    \"The story was dull and predictable.\",\n    \"A movie that was poorly made and uninteresting.\",\n    \"The film was a waste of my time.\",\n    \"A boring and lifeless movie.\",\n    \"The movie was a total disappointment.\"\n]\n\n# Generate 10,000 samples\nsamples = []\nfor i in range(10000):\n    if random.random() < 0.5:\n        sentiment = \"Positive\"\n        sentence = random.choice(positive_sentiments)\n    else:\n        sentiment = \"Negative\"\n        sentence = random.choice(negative_sentiments)\n    samples.append(f\"Example {i+1}:\\nSentence: \\\"{sentence}\\\"\")"},{"attachments":{},"cell_type":"markdown","id":"bb5bcc9a-0d9a-47fa-8f78-6f4cab0bd777","metadata":{"language":"python"},"source":"## Installing Vertex AI and Generative AI "},{"cell_type":"code","execution_count":74,"id":"a9ff031a-3bbf-4903-a762-8179b0b5c968","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:12:31.815359Z","iopub.status.busy":"2024-05-19T00:12:31.815093Z","iopub.status.idle":"2024-05-19T00:12:46.020639Z","shell.execute_reply":"2024-05-19T00:12:46.020059Z","shell.execute_reply.started":"2024-05-19T00:12:31.815331Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting google-generativeai\n  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\nCollecting google-ai-generativelanguage==0.6.4 (from google-generativeai)\n  Downloading google_ai_generativelanguage-0.6.4-py3-none-any.whl.metadata (5.6 kB)\nCollecting google-api-core (from google-generativeai)\n  Downloading google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting google-api-python-client (from google-generativeai)\n  Downloading google_api_python_client-2.129.0-py2.py3-none-any.whl.metadata (6.7 kB)\nCollecting google-auth>=2.15.0 (from google-generativeai)\n  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\nCollecting protobuf (from google-generativeai)\n  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting pydantic (from google-generativeai)\n  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from google-generativeai) (4.66.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from google-generativeai) (4.8.0)\nCollecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.4->google-generativeai)\n  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\nCollecting protobuf (from google-generativeai)\n  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.31.0)\nCollecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\nCollecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\nCollecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\nCollecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\nCollecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\nCollecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\nCollecting annotated-types>=0.4.0 (from pydantic->google-generativeai)\n  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\nCollecting pydantic-core==2.18.2 (from pydantic->google-generativeai)\n  Downloading pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nCollecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai)\n  Downloading grpcio-1.63.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nCollecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai)\n  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\nCollecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai)\n  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\nCollecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\nINFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\nCollecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai)\n  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\nDownloading google_generativeai-0.5.4-py3-none-any.whl (150 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_ai_generativelanguage-0.6.4-py3-none-any.whl (679 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.1/679.1 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_api_python_client-2.129.0-py2.py3-none-any.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\nDownloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\nDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\nDownloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\nDownloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\nDownloading grpcio-1.63.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\nDownloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: uritemplate, pyparsing, pydantic-core, pyasn1, protobuf, grpcio, cachetools, annotated-types, rsa, pydantic, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\nSuccessfully installed annotated-types-0.6.0 cachetools-5.3.3 google-ai-generativelanguage-0.6.4 google-api-core-2.19.0 google-api-python-client-2.129.0 google-auth-2.29.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.4 googleapis-common-protos-1.63.0 grpcio-1.63.0 grpcio-status-1.62.2 httplib2-0.22.0 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 pydantic-2.7.1 pydantic-core-2.18.2 pyparsing-3.1.2 rsa-4.9 uritemplate-4.1.1\nCollecting vertexai\n  Downloading vertexai-1.49.0-py3-none-any.whl.metadata (10 kB)\nCollecting google-cloud-aiplatform==1.49.0 (from google-cloud-aiplatform[all]==1.49.0->vertexai)\n  Downloading google_cloud_aiplatform-1.49.0-py2.py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (2.19.0)\nRequirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.11/site-packages (from google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (2.29.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (1.23.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.11/site-packages (from google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (4.25.3)\nRequirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.11/site-packages (from google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (23.2)\nCollecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai)\n  Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl.metadata (6.1 kB)\nCollecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai)\n  Downloading google_cloud_bigquery-3.23.0-py2.py3-none-any.whl.metadata (8.9 kB)\nCollecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai)\n  Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl.metadata (5.3 kB)\nCollecting shapely<3.0.0dev (from google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai)\n  Downloading shapely-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\nRequirement already satisfied: pydantic<3 in /opt/conda/lib/python3.11/site-packages (from google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (2.7.1)\nCollecting docstring-parser<1 (from google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai)\n  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n\u001b[33mWARNING: google-cloud-aiplatform 1.49.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (1.63.0)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (2.31.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (1.63.0)\nRequirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (1.62.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (5.3.3)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (4.9)\nCollecting google-cloud-core<3.0.0dev,>=1.6.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai)\n  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\nCollecting google-resumable-media<3.0dev,>=0.6.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai)\n  Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (2.8.2)\nCollecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai)\n  Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl.metadata (3.3 kB)\nCollecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai)\n  Downloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (2.18.2)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (4.8.0)\nRequirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.11/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (1.26.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (0.6.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (3.3.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.49.0->google-cloud-aiplatform[all]==1.49.0->vertexai) (2023.7.22)\nDownloading vertexai-1.49.0-py3-none-any.whl (7.3 kB)\nDownloading google_cloud_aiplatform-1.49.0-py2.py3-none-any.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\nDownloading google_cloud_bigquery-3.23.0-py2.py3-none-any.whl (237 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.1/237.1 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.7/333.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shapely-2.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\nDownloading google_crc32c-1.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\nDownloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\nInstalling collected packages: shapely, google-crc32c, docstring-parser, google-resumable-media, grpc-google-iam-v1, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform, vertexai\nSuccessfully installed docstring-parser-0.16 google-cloud-aiplatform-1.49.0 google-cloud-bigquery-3.23.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.12.3 google-cloud-storage-2.16.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 grpc-google-iam-v1-0.13.0 shapely-2.0.4 vertexai-1.49.0\n"}],"source":"!pip install google-generativeai\n!pip install vertexai"},{"attachments":{},"cell_type":"markdown","id":"1fd45961-cce5-45ee-9250-d23cca275d2a","metadata":{"language":"python"},"source":"## Gemini Text Output"},{"cell_type":"code","execution_count":78,"id":"7603d316-67b3-4f1b-9939-a15786909a19","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:13:28.551186Z","iopub.status.busy":"2024-05-19T00:13:28.550925Z","iopub.status.idle":"2024-05-19T00:13:28.554664Z","shell.execute_reply":"2024-05-19T00:13:28.554021Z","shell.execute_reply.started":"2024-05-19T00:13:28.551170Z"},"language":"python","trusted":true},"outputs":[],"source":"import google.generativeai as genai\ndef generate_response(model, prompt):\n    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n    if not gemini_api_key:\n        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n    genai.configure(api_key=gemini_api_key)\n    answer = model.generate_content([prompt])\n    return answer.text"},{"cell_type":"code","execution_count":88,"id":"6bd7062a-c2ce-4dcf-8475-fc91cda832c0","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:15:01.043875Z","iopub.status.busy":"2024-05-19T00:15:01.043586Z","iopub.status.idle":"2024-05-19T00:15:05.427007Z","shell.execute_reply":"2024-05-19T00:15:05.426357Z","shell.execute_reply.started":"2024-05-19T00:15:01.043850Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Here's a breakdown of the sentiment for each sentence:\n\n**Sentence: \"The visuals were impressive, but the story was lackluster.\"**\n**Sentiment: Negative** (While there's a positive element, the overall sentiment leans negative due to the \"lackluster\" story)\n\n**Sentence: \"A brilliant piece of cinema that left me speechless.\"**\n**Sentiment: Positive** (Clearly expresses strong positive emotion)\n\n**Sentence: \"The film was too long and uninteresting.\"**\n**Sentiment: Negative** (Both descriptors \"too long\" and \"uninteresting\" are negative)\n\n**Sentence: \"An engaging and well-crafted narrative.\"**\n**Sentiment: Positive** (\"Engaging\" and \"well-crafted\" are positive attributes) \n\n"}],"source":"model = genai.GenerativeModel('gemini-1.5-pro-latest')\nprint(generate_response(model, prompt))"},{"attachments":{},"cell_type":"markdown","id":"4f4992d4-9e80-4486-8c90-262824f507d8","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:16:55.771151Z","iopub.status.busy":"2024-05-19T00:16:55.770856Z","iopub.status.idle":"2024-05-19T00:16:55.777780Z","shell.execute_reply":"2024-05-19T00:16:55.777061Z","shell.execute_reply.started":"2024-05-19T00:16:55.771125Z"},"language":"python"},"source":"# Additional code to experiment with multimodal prompting and RAG to Gemini\n## The below sections contain extra code for the reader to try out prompting with modalities beyond text and RAG."},{"attachments":{},"cell_type":"markdown","id":"45b5b371-9f25-461b-ae19-0be80c4442de","metadata":{"language":"python"},"source":"# Image Input to Gemini"},{"cell_type":"code","execution_count":80,"id":"36bece1d-40ed-44a1-bccd-63466ac59935","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:13:30.052575Z","iopub.status.busy":"2024-05-19T00:13:30.052015Z","iopub.status.idle":"2024-05-19T00:13:38.487616Z","shell.execute_reply":"2024-05-19T00:13:38.486735Z","shell.execute_reply.started":"2024-05-19T00:13:30.052554Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  349k  100  349k    0     0  2207k      0 --:--:-- --:--:-- --:--:-- 2210k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 4835k  100 4835k    0     0  18.4M      0 --:--:-- --:--:-- --:--:-- 18.5M\nUploaded file 'Sample drawing' as: https://generativelanguage.googleapis.com/v1beta/files/8kci761hrkbn\nRetrieved file 'Sample drawing' as: https://generativelanguage.googleapis.com/v1beta/files/8kci761hrkbn\nScrawled on a sheet of ruled paper, a vision of the future takes shape: the Jetpack Backpack. A simple sketch of a backpack, seemingly ordinary with its padded straps, hides a revolutionary secret. Tucked beneath, retractable boosters promise a swift and exhilarating departure from the mundane.  This marvel of engineering, powered by clean, green steam, boasts an impressive 15-minute battery life, enough for a quick commute or a daring escape. Lightweight and disguised as a normal backpack, it's the ultimate solution for the busy urbanite who dreams of soaring above the traffic. This whimsical drawing is a testament to the human imagination, a playful reminder that sometimes the most fantastical ideas can be just a doodle away. \nDeleted Sample drawing.\n"}],"source":"# !curl -o image.jpg https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\n# !curl -O https://storage.googleapis.com/github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\n# sample_file = genai.upload_file(path=\"image.jpg\", display_name=\"Sample drawing\")\n# print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")\n# file = genai.get_file(name=sample_file.name)\n# print(f\"Retrieved file '{file.display_name}' as: {sample_file.uri}\")\n# # Set the model to Gemini 1.5 Pro.\n# model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\n# response = model.generate_content([\"Describe the image with a creative description.\", sample_file])\n# print(response.text, end=\"\")\n# # Markdown(\">\" + response.text)\n# genai.delete_file(sample_file.name)\n# print(f'Deleted {sample_file.display_name}.')"},{"attachments":{},"cell_type":"markdown","id":"3bdd80a4-8a3f-4483-bf4b-be50ce86cc4b","metadata":{"language":"python"},"source":"Video Input to Gemini"},{"cell_type":"code","execution_count":81,"id":"423d3eed-e50e-4c23-8002-d56ecab0b8b8","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:13:38.493400Z","iopub.status.busy":"2024-05-19T00:13:38.493046Z","iopub.status.idle":"2024-05-19T00:13:38.497459Z","shell.execute_reply":"2024-05-19T00:13:38.496977Z","shell.execute_reply.started":"2024-05-19T00:13:38.493381Z"},"language":"python","trusted":true},"outputs":[],"source":"# video_file_name = \"https://download.blender.org/peach/bigbuckbunny_movies/BigBuckBunny_320x180.mp4\""},{"attachments":{},"cell_type":"markdown","id":"b4997b48-09c2-4ec4-a480-73f14f1961a0","metadata":{"language":"python"},"source":"### Feeding in Video to Gemini"},{"cell_type":"code","execution_count":82,"id":"8abfb5e1-ea84-48ed-9147-b5efabdff1c3","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:13:38.499359Z","iopub.status.busy":"2024-05-19T00:13:38.499042Z","iopub.status.idle":"2024-05-19T00:13:38.502634Z","shell.execute_reply":"2024-05-19T00:13:38.502113Z","shell.execute_reply.started":"2024-05-19T00:13:38.499340Z"},"language":"python","trusted":true},"outputs":[],"source":"# import cv2\n# import os\n# import shutil\n# \n# # Create or cleanup existing extracted image frames directory.\n# FRAME_EXTRACTION_DIRECTORY = \"content/frames\"\n# FRAME_PREFIX = \"_frame\"\n# def create_frame_output_dir(output_dir):\n#   if not os.path.exists(output_dir):\n#     os.makedirs(output_dir)\n#   else:\n#     shutil.rmtree(output_dir)\n#     os.makedirs(output_dir)\n# \n# def extract_frame_from_video(video_file_path):\n#   print(f\"Extracting {video_file_path} at 1 frame per second. This might take a bit...\")\n#   create_frame_output_dir(FRAME_EXTRACTION_DIRECTORY)\n#   vidcap = cv2.VideoCapture(video_file_path)\n#   fps = vidcap.get(cv2.CAP_PROP_FPS)\n#   print(fps)\n#   frame_duration = 1 / fps  # Time interval between frames (in seconds)\n#   output_file_prefix = os.path.basename(video_file_path).replace('.', '_')\n#   frame_count = 0\n#   count = 0\n#   while vidcap.isOpened():\n#       success, frame = vidcap.read()\n#       if not success: # End of video\n#           break\n#       if int(count / fps) == frame_count: # Extract a frame every second\n#           min = frame_count // 60\n#           sec = frame_count % 60\n#           time_string = f\"{min:02d}:{sec:02d}\"\n#           image_name = f\"{output_file_prefix}{FRAME_PREFIX}{time_string}.jpg\"\n#           output_filename = os.path.join(FRAME_EXTRACTION_DIRECTORY, image_name)\n#           cv2.imwrite(output_filename, frame)\n#           frame_count += 1\n#       count += 1\n#   vidcap.release() # Release the capture object\\n\",\n#   print(f\"Completed video frame extraction!\\n\\nExtracted: {frame_count} frames\")\n# \n# extract_frame_from_video(video_file_name)"},{"cell_type":"code","execution_count":83,"id":"c2bc2cc9-8c32-4a6e-a28a-3cb250147bd8","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:13:38.503654Z","iopub.status.busy":"2024-05-19T00:13:38.503353Z","iopub.status.idle":"2024-05-19T00:13:38.507760Z","shell.execute_reply":"2024-05-19T00:13:38.507301Z","shell.execute_reply.started":"2024-05-19T00:13:38.503637Z"},"language":"python","trusted":true},"outputs":[],"source":"# import os\n# \n# class File:\n#   def __init__(self, file_path: str, display_name: str = None):\n#     self.file_path = file_path\n#     if display_name:\n#       self.display_name = display_name\n#     self.timestamp = get_timestamp(file_path)\n# \n#   def set_file_response(self, response):\n#     self.response = response\n# \n# def get_timestamp(filename):\n#   \"\"\"Extracts the frame count (as an integer) from a filename with the format\n#      'output_file_prefix_frame00:00.jpg'.\n#   \"\"\"\n#   parts = filename.split(FRAME_PREFIX)\n#   if len(parts) != 2:\n#       return None  # Indicates the filename might be incorrectly formatted\n#   return parts[1].split('.')[0]\n# \n# # Process each frame in the output directory\n# files = os.listdir(FRAME_EXTRACTION_DIRECTORY)\n# files = sorted(files)\n# files_to_upload = []\n# for file in files:\n#   files_to_upload.append(\n#       File(file_path=os.path.join(FRAME_EXTRACTION_DIRECTORY, file)))\n# \n# # Upload the files to the API\n# # Only upload a 10 second slice of files to reduce upload time.\n# # Change full_video to True to upload the whole video.\n# full_video = False\n# \n# uploaded_files = []\n# print(f'Uploading {len(files_to_upload) if full_video else 10} files. This might take a bit...')\n# \n# for file in files_to_upload if full_video else files_to_upload[40:50]:\n#   print(f'Uploading: {file.file_path}...')\n#   response = genai.upload_file(path=file.file_path)\n#   file.set_file_response(response)\n#   uploaded_files.append(file)\n# \n# print(f\"Completed file uploads!\\n\\nUploaded: {len(uploaded_files)} files\")"},{"cell_type":"code","execution_count":89,"id":"8183852b-43c5-4139-ad86-16cc404b1a7a","metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:15:37.722564Z","iopub.status.busy":"2024-05-19T00:15:37.722227Z","iopub.status.idle":"2024-05-19T00:15:37.726517Z","shell.execute_reply":"2024-05-19T00:15:37.725845Z","shell.execute_reply.started":"2024-05-19T00:15:37.722533Z"},"language":"python","trusted":true},"outputs":[],"source":"# List files uploaded in the API\n# for n, f in zip(range(len(uploaded_files)), genai.list_files()):\n#  print(f.uri)"},{"attachments":{},"cell_type":"markdown","id":"24415c08-44f2-4856-bef3-6e87a5a2fad9","metadata":{"language":"python"},"source":"## Multimodal input to Gemini: Text and Video"},{"cell_type":"code","execution_count":null,"id":"5de3433b-2719-40d3-8f2e-3e198cd6a740","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.527476Z","iopub.status.idle":"2024-05-19T00:13:38.527938Z","shell.execute_reply":"2024-05-19T00:13:38.527819Z","shell.execute_reply.started":"2024-05-19T00:13:38.527807Z"},"language":"python","trusted":true},"outputs":[],"source":"# Create the prompt.\n# prompt = \"Summarize the above text and then describe this video.\"\n# prompt = pdf_text + prompt\n# \n# # Set the model to Gemini 1.5 Pro.\n# model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")\n# \n# # Make GenerateContent request with the structure described above.\n# def make_request(prompt, files):\n#   request = [prompt]\n#   for file in files:\n#     request.append(file.timestamp)\n#     request.append(file.response)\n#   return request\n# \n# # Make the LLM request.\n# #request = make_request([pdf_text, prompt], uploaded_files)\n# request = make_request(prompt, uploaded_files)\n# response = model.generate_content(request,\n#                                   request_options={\"timeout\": 600})\n# print(response.text)"},{"cell_type":"code","execution_count":null,"id":"09b41346-ef56-49c7-99a3-2da955c42e0f","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.528668Z","iopub.status.idle":"2024-05-19T00:13:38.528900Z","shell.execute_reply":"2024-05-19T00:13:38.528793Z","shell.execute_reply.started":"2024-05-19T00:13:38.528783Z"},"language":"python","trusted":true},"outputs":[],"source":"#print(f'Deleting {len(uploaded_files)} images. This might take a bit...')\n#for file in uploaded_files:\n#  genai.delete_file(file.response.name)\n#  print(f'Deleted {file.file_path} at URI {file.response.uri}')\n#print(f\"Completed deleting files!\\n\\nDeleted: {len(uploaded_files)} files\")"},{"attachments":{},"cell_type":"markdown","id":"1c7aa32c-8876-4cf5-98bb-91b261226e6d","metadata":{"execution":{"iopub.execute_input":"2024-04-15T07:18:12.967468Z","iopub.status.busy":"2024-04-15T07:18:12.967158Z","iopub.status.idle":"2024-04-15T07:18:12.970441Z","shell.execute_reply":"2024-04-15T07:18:12.969903Z","shell.execute_reply.started":"2024-04-15T07:18:12.967444Z"},"language":"python"},"source":"# Retrieval Augmented Generation"},{"cell_type":"code","execution_count":null,"id":"8bd6f4de-0f6f-4bdd-9551-5969b2a8c6eb","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.529671Z","iopub.status.idle":"2024-05-19T00:13:38.529959Z","shell.execute_reply":"2024-05-19T00:13:38.529840Z","shell.execute_reply.started":"2024-05-19T00:13:38.529829Z"},"language":"python","trusted":true},"outputs":[],"source":"# !pip install wget --quiet\n# !pip install openai==1.3.3 --quiet"},{"cell_type":"code","execution_count":null,"id":"0f73ddb2-62fe-4554-b981-f40c858f9505","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.530784Z","iopub.status.idle":"2024-05-19T00:13:38.531030Z","shell.execute_reply":"2024-05-19T00:13:38.530917Z","shell.execute_reply.started":"2024-05-19T00:13:38.530907Z"},"language":"python","trusted":true},"outputs":[],"source":"# import json\n# import os\n# import pandas as pd\n# import wget"},{"cell_type":"code","execution_count":null,"id":"e36266bb-7e3f-4d81-b500-49d5ec1e8b28","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.531844Z","iopub.status.idle":"2024-05-19T00:13:38.532072Z","shell.execute_reply":"2024-05-19T00:13:38.531968Z","shell.execute_reply.started":"2024-05-19T00:13:38.531957Z"},"language":"python","trusted":true},"outputs":[],"source":"# Import the library for vectorizing the data (Up to 2 minutes)\n# !pip install sentence-transformers --quiet\n# \n# from sentence_transformers import SentenceTransformer\n# \n# modelRAG = SentenceTransformer('flax-sentence-embeddings/all_datasets_v3_mpnet-base')"},{"cell_type":"code","execution_count":null,"id":"39cdd52d-8e10-4bee-aa61-9c5ab11a5b3e","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.532904Z","iopub.status.idle":"2024-05-19T00:13:38.533153Z","shell.execute_reply":"2024-05-19T00:13:38.533038Z","shell.execute_reply.started":"2024-05-19T00:13:38.533028Z"},"language":"python","trusted":true},"outputs":[],"source":"# download reviews csv file\n# cvs_file_path = 'https://raw.githubusercontent.com/openai/openai-cookbook/main/examples/data/AG_news_samples.csv'\n# file_path = 'AG_news_samples.csv'\n# \n# if not os.path.exists(file_path):\n#     wget.download(cvs_file_path, file_path)\n#     print('File downloaded successfully.')\n# else:\n#     print('File already exists in the local file system.')"},{"cell_type":"code","execution_count":null,"id":"1c1e5c6d-af1e-4a3e-bb9f-e73f163c602f","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.535244Z","iopub.status.idle":"2024-05-19T00:13:38.535514Z","shell.execute_reply":"2024-05-19T00:13:38.535397Z","shell.execute_reply.started":"2024-05-19T00:13:38.535386Z"},"language":"python","trusted":true},"outputs":[],"source":"# df = pd.read_csv('AG_news_samples.csv')\n# df"},{"cell_type":"code","execution_count":null,"id":"23210387-1883-4e46-8ac6-bec8714e39bb","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.536315Z","iopub.status.idle":"2024-05-19T00:13:38.536547Z","shell.execute_reply":"2024-05-19T00:13:38.536441Z","shell.execute_reply.started":"2024-05-19T00:13:38.536432Z"},"language":"python","trusted":true},"outputs":[],"source":"# data = df.to_dict(orient='records')\n# data[0]"},{"cell_type":"code","execution_count":null,"id":"bae8d824-4e6b-4c03-815b-d446b7ff910f","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.537350Z","iopub.status.idle":"2024-05-19T00:13:38.537581Z","shell.execute_reply":"2024-05-19T00:13:38.537476Z","shell.execute_reply.started":"2024-05-19T00:13:38.537466Z"},"language":"python","trusted":true},"outputs":[],"source":"# shared_tier_check = %sql show variables like 'is_shared_tier'\n# if not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n#     %sql DROP DATABASE IF EXISTS news;\n#     %sql CREATE DATABASE news;"},{"cell_type":"code","execution_count":null,"id":"d774ec11-de67-44d3-b8a1-3c8a8377bcbb","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.538391Z","iopub.status.idle":"2024-05-19T00:13:38.538636Z","shell.execute_reply":"2024-05-19T00:13:38.538526Z","shell.execute_reply.started":"2024-05-19T00:13:38.538516Z"},"language":"python","trusted":true},"outputs":[],"source":"# %%sql\n# DROP TABLE IF EXISTS news_articles;\n# CREATE TABLE IF NOT EXISTS news_articles (\n#     title TEXT,\n#     description TEXT,\n#     genre TEXT,\n#     embedding BLOB,\n#     FULLTEXT (title, description)\n# );"},{"cell_type":"code","execution_count":null,"id":"8bd217fd-1ed0-4394-9749-d70f40a53048","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.539505Z","iopub.status.idle":"2024-05-19T00:13:38.539783Z","shell.execute_reply":"2024-05-19T00:13:38.539638Z","shell.execute_reply.started":"2024-05-19T00:13:38.539628Z"},"language":"python","trusted":true},"outputs":[],"source":"# Will take around 3.5 minutes to get embeddings for all 2000 rows\n\n# descriptions = [row['description'] for row in data]\n# all_embeddings = modelRAG.encode(descriptions)\n# all_embeddings.shape"},{"cell_type":"code","execution_count":null,"id":"959825f0-469f-4891-88b7-fb054f8f3b7f","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.540563Z","iopub.status.idle":"2024-05-19T00:13:38.540793Z","shell.execute_reply":"2024-05-19T00:13:38.540689Z","shell.execute_reply.started":"2024-05-19T00:13:38.540678Z"},"language":"python","trusted":true},"outputs":[],"source":"# for row, embedding in zip(data, all_embeddings):\n#     row['embedding'] = embedding"},{"cell_type":"code","execution_count":null,"id":"52a4b172-170c-4636-9fe7-bda994d93152","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.541638Z","iopub.status.idle":"2024-05-19T00:13:38.541902Z","shell.execute_reply":"2024-05-19T00:13:38.541766Z","shell.execute_reply.started":"2024-05-19T00:13:38.541756Z"},"language":"python","scrolled":true,"trusted":true},"outputs":[],"source":"# data[0]"},{"cell_type":"code","execution_count":null,"id":"a6daa73f-3ad5-40e2-ade7-ccbf07a37101","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.542709Z","iopub.status.idle":"2024-05-19T00:13:38.542956Z","shell.execute_reply":"2024-05-19T00:13:38.542844Z","shell.execute_reply.started":"2024-05-19T00:13:38.542834Z"},"language":"python","trusted":true},"outputs":[],"source":"# %sql TRUNCATE TABLE news_articles;\n# \n# import sqlalchemy as sa\n# from singlestoredb import create_engine\n# \n# # Use create_table from singlestoredb since it uses the notebook connection URL\n# conn = create_engine().connect()\n# \n# statement = sa.text('''\n#         INSERT INTO news_articles (\n#             title,\n#             description,\n#             genre,\n#             embedding\n#         )\n#         VALUES (\n#             :title,\n#             :description,\n#             :label,\n#             :embedding\n#         )\n#     ''')\n# \n# conn.execute(statement, data)"},{"cell_type":"code","execution_count":null,"id":"7a7927ae-5125-4099-aeba-5a4f3093343c","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.543657Z","iopub.status.idle":"2024-05-19T00:13:38.543920Z","shell.execute_reply":"2024-05-19T00:13:38.543814Z","shell.execute_reply.started":"2024-05-19T00:13:38.543803Z"},"language":"python","trusted":true},"outputs":[],"source":"#search_query = 'Articles about Aussie captures'\n# search_query = 'Aussie'\n# search_embedding = modelRAG.encode(search_query)\n# \n# query_statement = sa.text('''\n#     SELECT\n#         title,\n#         description,\n#         genre,\n#         DOT_PRODUCT(embedding, :embedding) AS score\n#     FROM news_articles\n#     ORDER BY score DESC\n#     LIMIT 10\n#     ''')\n# \n# \n# # Execute the SQL statement.\n# results = pd.DataFrame(conn.execute(query_statement, dict(embedding=search_embedding)))\n# print(results)"},{"cell_type":"code","execution_count":null,"id":"e162945e-255e-40f4-a6ca-914970f16683","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.544900Z","iopub.status.idle":"2024-05-19T00:13:38.545142Z","shell.execute_reply":"2024-05-19T00:13:38.545033Z","shell.execute_reply.started":"2024-05-19T00:13:38.545022Z"},"language":"python","trusted":true},"outputs":[],"source":"# Hybrid search for \"Articles about Aussie captures\"\n# hyb_query = 'Articles about Aussie captures'\n# hyb_embedding = modelRAG.encode(hyb_query)\n# \n# # Create the SQL statement.\n# hyb_statement = sa.text('''\n#     SELECT\n#         title,\n#         description,\n#         genre,\n#         DOT_PRODUCT(embedding, :embedding) AS semantic_score,\n#         MATCH(title, description) AGAINST (:query) AS keyword_score,\n#         (semantic_score + keyword_score) / 2 AS combined_score\n#     FROM news_articles\n#     ORDER BY combined_score DESC\n#     LIMIT 10\n#     ''')\n# \n# # Execute the SQL statement.\n# hyb_results = pd.DataFrame(conn.execute(hyb_statement, dict(embedding=hyb_embedding, query=hyb_query)))\n# hyb_results"},{"cell_type":"code","execution_count":null,"id":"74c0af5b-fae3-4c15-89f3-1e3dd9a210b4","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.545986Z","iopub.status.idle":"2024-05-19T00:13:38.546232Z","shell.execute_reply":"2024-05-19T00:13:38.546119Z","shell.execute_reply.started":"2024-05-19T00:13:38.546108Z"},"language":"python","trusted":true},"outputs":[],"source":"# import google.generativeai as genai\n# def generate_response(modelRAG, prompt):\n#     gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n#     if not gemini_api_key:\n#         raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n#     genai.configure(api_key=gemini_api_key)\n#     answer = modelRAG.generate_content([pdf_text, prompt])\n#     return answer.text\n# \n# modelRAG = genai.GenerativeModel('gemini-1.5-pro-latest')\n# results_string = hyb_results.to_string()\n# print(generate_response(modelRAG, hyb_query + results_string))"},{"attachments":{},"cell_type":"markdown","id":"abb11803-2ab3-4de6-8d01-6f8fae4cb145","metadata":{"language":"python"},"source":"# Clean up"},{"cell_type":"code","execution_count":null,"id":"3072201f-5ef1-476f-ab68-382be6bcaf75","metadata":{"execution":{"iopub.status.busy":"2024-05-19T00:13:38.546967Z","iopub.status.idle":"2024-05-19T00:13:38.547199Z","shell.execute_reply":"2024-05-19T00:13:38.547092Z","shell.execute_reply.started":"2024-05-19T00:13:38.547082Z"},"language":"python","trusted":true},"outputs":[],"source":"# shared_tier_check = %sql show variables like 'is_shared_tier'\n# if not shared_tier_check or shared_tier_check[0][1] == 'OFF':\n#     %sql DROP DATABASE IF EXISTS news;"},{"cell_type":"code","execution_count":null,"id":"184be3a9-700e-49cf-a376-a8b46a12205c","metadata":{"language":"python","trusted":true},"outputs":[],"source":""}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"1ef09419-817e-4b95-8f8f-5339a10ae674","defaultDatabase":"database_0311a"}},"nbformat":4,"nbformat_minor":5}