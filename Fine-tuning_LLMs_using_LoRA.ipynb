{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-05-18T22:53:30.539420Z","iopub.status.busy":"2024-05-18T22:53:30.539146Z","iopub.status.idle":"2024-05-18T22:53:30.541699Z","shell.execute_reply":"2024-05-18T22:53:30.541334Z","shell.execute_reply.started":"2024-05-18T22:53:30.539404Z"},"language":"python"},"source":"<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(209, 153, 255, 0.25); padding: 5px;\">\n    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/vector-circle.png\" />\n    </div>\n    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Fine-tuning LLMs using LoRA (for a Marketing/Sentiment Analysis Usecase)\n        </h1>\n    </div>\n</div>"},{"cell_type":"code","execution_count":130,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T23:50:39.799330Z","iopub.status.busy":"2024-05-18T23:50:39.799069Z","iopub.status.idle":"2024-05-18T23:50:50.633480Z","shell.execute_reply":"2024-05-18T23:50:50.632835Z","shell.execute_reply.started":"2024-05-18T23:50:39.799314Z"},"id":"smZAvuwTRs3v","language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"},{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (2.19.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.13.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.2)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (12.0.1)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.23.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.2->datasets) (4.8.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"},{"name":"stderr","output_type":"stream","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"},{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.41.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.4)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.23.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.4.16)\nRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.8.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n"},{"name":"stderr","output_type":"stream","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"},{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (0.11.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft) (1.26.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft) (23.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft) (5.9.5)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft) (2.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft) (4.41.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.30.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.11/site-packages (from peft) (0.23.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (4.8.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\nRequirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (2024.4.16)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"},{"name":"stderr","output_type":"stream","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"},{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: evaluate in /opt/conda/lib/python3.11/site-packages (0.4.2)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.19.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate) (1.26.2)\nRequirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate) (0.23.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate) (23.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.13.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (12.0.1)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.3.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"},{"name":"stderr","output_type":"stream","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"},{"name":"stdout","output_type":"stream","text":"Collecting sklearn\n  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m More information is available at\n  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[?25h"}],"source":"!pip install datasets\n!pip install transformers\n!pip install peft\n!pip install evaluate\n!pip install sklearn"},{"cell_type":"code","execution_count":131,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T23:50:50.636587Z","iopub.status.busy":"2024-05-18T23:50:50.636292Z","iopub.status.idle":"2024-05-18T23:50:50.639885Z","shell.execute_reply":"2024-05-18T23:50:50.639341Z","shell.execute_reply.started":"2024-05-18T23:50:50.636562Z"},"id":"nHI_3okURigd","language":"python","trusted":true},"outputs":[],"source":"from datasets import load_dataset, DatasetDict, Dataset\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoConfig,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    TrainingArguments,\n    Trainer)\n\nfrom peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\nimport evaluate\nimport torch\nimport numpy as np"},{"attachments":{},"cell_type":"markdown","metadata":{"id":"glO5VLLAV6kj"},"source":"# Load the Stanford Sentiment Treebank v2 (SST2) dataset for Sentiment Analysis"},{"cell_type":"code","execution_count":132,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388,"referenced_widgets":["608531c3fa53455f85e6f75b11464eef","9d8592e2e12a446e91c3bd631a757376","87e03d3bcb49401b92b4aa510efebc0b","5e9e3efa02b64e32a0216a3021277f6c","f4573181f6cd41c8a3cdcf4a4b36cedb","9e168c6cd1704b3181018ed0972b4af2","a83d02a84b534d908928d77063655de0","1aa33fccf4d54e93aa5682cfbcc125f9","a256e37bfdf047b2bba6024c3d075744","800a545af8374da1a376936daf876ea4","650dc2be288d40b4b1c1e409efae6c0c","da05b4cde98946b9a907110817dce69e","8a4d508edb924691bc5356b42dac2167","d6a0dbffe795442bba4f1eec85e05f7d","2328bf6c01284c80a27175917c13a7f0","fc0a64278885452ca6d603372c1d3b6f","d9f82343dca14bfdb25d8abca6d8615e","ebc84f46af9a4a1494495586b9e57bdd","24ff305caebf4bd98115f28f1b60969a","f28a27404f1142c593164f58ec6b90c4","c784370270884bfaaa69c87b2cd74ba2","122d68c6fdb14d919a6dc452941320c0","0d09e4bccb644193ae1e8f869305cb85","36d5641488ac45d7a367c03bb3bf2257","e3ba71f6278240dcb15b9bf12a69cdff","8ca745cc301f49a8bb983dbbb1d6c9a2","09d7a912b8064d11812f705f25d569a7","f77345d53af841df90d892dea32891f2","2bef788d0efc49dcaf5cf0d8b216c701","0de29d93f0f742119fd54fdded1562ad","36f3356dcc5c4bf4a8ea3cec09581d4e","74eeef847b8941faa77a86b9a9335fed","b34450ab3e014466b7fd7c3edb7b78d8","6fc2bc5372824a6ab1bc78f62c2a04d3","afbdace8812e43a49c851ff1a52be1fa","eb52f4279d50447093d27d126f6d64a8","a3f9acbf9aed48fd9586908ee7060ba9","394d8941fab24809b109d1a21ea8d8b1","c84a57ad81f548eca27e7c9138e14721","e5e69bc88a8c489c90f75bf6c286dc52","004f6b985ecc4a3683e994e7abf0caeb","f532bbd81f1243d98e1eff03a51d8796","2dc833f6d70f48d7b8cf451d3308500e","32f29b5ca94d472fb9f81330da60f2f2"]},"execution":{"iopub.execute_input":"2024-05-18T23:50:50.641070Z","iopub.status.busy":"2024-05-18T23:50:50.640791Z","iopub.status.idle":"2024-05-18T23:50:51.626316Z","shell.execute_reply":"2024-05-18T23:50:51.625836Z","shell.execute_reply.started":"2024-05-18T23:50:50.641052Z"},"id":"MRnSWdB1g4ah","language":"python","outputId":"3e93d790-c71f-4510-be80-3b63fffb1e87","trusted":true},"outputs":[{"data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 67349\n    })\n    validation: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 1821\n    })\n})"},"execution_count":132,"metadata":{},"output_type":"execute_result"}],"source":"# sst2\n# The Stanford Sentiment Treebank consists of sentences from movie reviews and human annotations of their sentiment. The task is to predict the sentiment of a given sentence. It uses the two-way (positive/negative) class split, with only sentence-level labels.\ndataset = load_dataset(\"glue\", \"sst2\")\ndataset"},{"cell_type":"code","execution_count":133,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-18T23:50:51.627266Z","iopub.status.busy":"2024-05-18T23:50:51.627055Z","iopub.status.idle":"2024-05-18T23:50:51.680189Z","shell.execute_reply":"2024-05-18T23:50:51.679573Z","shell.execute_reply.started":"2024-05-18T23:50:51.627247Z"},"id":"Wnfwkc9VSVHc","language":"python","outputId":"1d8994b6-4d9a-49fd-bc12-e3e703816f11","trusted":true},"outputs":[{"data":{"text/plain":"0.5578256544269403"},"execution_count":133,"metadata":{},"output_type":"execute_result"}],"source":"# display % of training data with label=1\nnp.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9w7RcqFVV-hI"},"source":"# Load model"},{"cell_type":"code","execution_count":134,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["f793f946b2d247c38d25f264efd5e743","5004e87e5be944de8af1ff6bbddb6df1","7797e1f8b3bf41bca491f33dff0e09a4","cdfd68b66e5a458b9561064c11d6a909","dd8a7f5b2546472e8455f36924e15ae4","26f84b41d4fa47cf9e307df9740a02c6","ebdc60227ab44915af5ccf2e4a078745","2c9b3475a6824ef5a1c14a1c03163efd","ab392e83bfc1459b8e32332c1c4584d4","e70953d6ab4b40a9bcd2269c8d3fd1f8","609826e908334141850672335afc3a26","8b5d1ff6cb404400a23dfdd55b7d6468","1bd4f53c723147478d095ac352303079","f1259d83b99d4f4abfa31b7884188056","e883d3e8c0ce441fa15cf2f683611c86","6d4d31f792f84e1e9e97072ba30674f5","6b42e896d0a44d878cfbbc16569b1e3a","c8fa95fd3e1c4b7fbd2cf8171fcc6346","0c66fc8fbcca458eb6c140d8f31fda2a","0345561dde714a4ab4b15dec1b1b68b3","be037dce8a9c458faef974dadde14f95","3294c9b17bec487c805c4a9369c77244"]},"execution":{"iopub.execute_input":"2024-05-18T23:50:51.682225Z","iopub.status.busy":"2024-05-18T23:50:51.682008Z","iopub.status.idle":"2024-05-18T23:50:51.949492Z","shell.execute_reply":"2024-05-18T23:50:51.948991Z","shell.execute_reply.started":"2024-05-18T23:50:51.682208Z"},"id":"ptr7HbwqSsa0","language":"python","outputId":"dff1f80e-101c-493c-c773-92b474842718","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"}],"source":"model_checkpoint = 'roberta-base'\n#model_checkpoint = 'google/flan-t5-xxl'\n\n# define label maps\nid2label = {0: \"Negative\", 1: \"Positive\"}\nlabel2id = {\"Negative\":0, \"Positive\":1}\n\n# generate classification model from model_checkpoint\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)"},{"cell_type":"code","execution_count":135,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-18T23:50:51.950689Z","iopub.status.busy":"2024-05-18T23:50:51.950464Z","iopub.status.idle":"2024-05-18T23:50:51.955176Z","shell.execute_reply":"2024-05-18T23:50:51.954596Z","shell.execute_reply.started":"2024-05-18T23:50:51.950667Z"},"id":"8vnFth_CS0Ec","language":"python","outputId":"374aaefd-9caa-4301-f90c-4c612676e9a8","trusted":true},"outputs":[{"data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"execution_count":135,"metadata":{},"output_type":"execute_result"}],"source":"# display architecture\nmodel"},{"attachments":{},"cell_type":"markdown","metadata":{"id":"a8az9-hQWCFo"},"source":"# Data Preprocessing"},{"cell_type":"code","execution_count":136,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["3f972a34d37d455b88f740084a59f9a0","daa4adfcc397415386147b663c0fb9f5","5b5688ec0e0b4e8091683c432f092f85","832ab959185042fea7a2e1fd7defba93","ca96131d8ec14ef38fcc627f1d705b58","cd45c914bd5e42a8a3757623c00a56a4","111ae998b44049a18a843e4aea81492d","32f329d15e01479e946393c0a5e0b6d0","0d743c4a7f8147d2bd5179aab3249054","859589b664544b6387ee3e96fdf46770","e81c131741d54dabaca8228b27baa6db","a43ebf5587ea4897a003d5790f6c1dd8","3f6dd4a81831404a870313f085b376e0","26baf7941801407886286087c2d42da7","28194c233db841c2bc23cd2a4f2faccc","e8b7e4ed5f864dee81479030ce0e417d","2fa22649b50b4b609a0fe5e677d24bf5","5dfa530e7c604db792a0ddaa75ad6f5b","a281a857d66747728e545ba05d0dd237","c30275e3e8df4a12a2ee52b50a5cde6f","f1bc0990d72b4a8fa7e8999687d6618d","c27329a8fe2c418e9710aa0976267539","d408dbc1d5c54e3297f71db6022020f5","305609bc186347b1b6465ee7ce5efab3","821dac12b93b4184aa746d9187f99324","ce71de5525704225936730d4154fe053","e41aae9c27bf43cc8a51d6521685e227","80abf21e74ce497c9c7daffa9ce69ec3","ef47fb69ccf14aa9a3db7ab5db73b280","0be7b958f0e8415eb63c30d1edc69951","20a879fd53c54a22bf1055b299f798dc","67dd35f4d225455893863ded95e80b6f","090d5d3d8be04cac85dd01ac08829a48"]},"execution":{"iopub.execute_input":"2024-05-18T23:50:51.956285Z","iopub.status.busy":"2024-05-18T23:50:51.956092Z","iopub.status.idle":"2024-05-18T23:50:52.048203Z","shell.execute_reply":"2024-05-18T23:50:52.047705Z","shell.execute_reply.started":"2024-05-18T23:50:51.956269Z"},"id":"DpL518OqS3ik","language":"python","outputId":"a3d23c55-da84-46fd-822e-e5dce70ef227","trusted":true},"outputs":[],"source":"# create tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n\n# add pad token if none exists\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))"},{"cell_type":"code","execution_count":137,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T23:50:52.049285Z","iopub.status.busy":"2024-05-18T23:50:52.049077Z","iopub.status.idle":"2024-05-18T23:50:52.053536Z","shell.execute_reply":"2024-05-18T23:50:52.052352Z","shell.execute_reply.started":"2024-05-18T23:50:52.049267Z"},"id":"h6TUa-tWS6k-","language":"python","trusted":true},"outputs":[],"source":"# create tokenize function\ndef tokenize_function(examples):\n    # extract text\n    text = examples[\"sentence\"]\n\n    #tokenize and truncate text\n    tokenizer.truncation_side = \"left\"\n    tokenized_inputs = tokenizer(\n        text,\n        return_tensors=\"np\",\n        truncation=True,\n        max_length=512\n    )\n\n    return tokenized_inputs"},{"cell_type":"code","execution_count":138,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356,"referenced_widgets":["a55d99fa95314ce6886cd37d9a204ffd","693a454312164ad497fa8708dfef72dc","73255411abfa4a46ac59cc9f7fb6d0b9","9fd39a3acbc1499b92e10623b64d6e4a","4b7b8085ddf244ab9075aa364d31e775","b09736bfd44044f999f6fe596ad93824","cd5f0eb7a4724310a00d0c23721131e2","a69f29226fe7497cba4ab16014c96a1d","92855a5f3c2f4924bef604059a698930","1957ceec2b684392b89ac64f89ce971a","325a12cb1a9c4263b2eb4c42f91ec6ac","1f2407bc20e342b8b43fe80071523d16","e299a3a372dc4765a2c37dfd98fa2a68","c83d451ae1ac42169395c2c380c16a77","4ef319938c114c8990e7ddbf9365529c","9178234fdae84e50932153a08f30be5b","d04da6f3e8fa4b21b20c82ba4ecac01f","b167de24bda4447db4a3bf970f6e9089","e15c234a473f4ffd8df852ab43b9bcff","4681611565bf45a48110cc8b79b16eb9","6632bac84bf04731af57d00f69eeed2f","b66c5816ebe64629ab02b47f3f39cc15","0575dcd029cc49439a66abe05566a7ce","a65524e3cd984456be764eee1ab27bde","1e15ea4be9974942917f8e5cc2bc0387","946ecf4844e64b3694741f99ff865cbc","82aa12592c3c4639b2f23c5d664d680b","32a9119a11914198ad3b758d50b456b0","b5349cfa270c4054a57d683d021b0581","702decebc3eb471687604280da061d01","577c730f73684ed2a0ce9bb4556672c3","b994a8d40a064a0b97a524799a6e6590","60cd5a168efd4c7da7297a84ff39725b"]},"execution":{"iopub.execute_input":"2024-05-18T23:50:52.054697Z","iopub.status.busy":"2024-05-18T23:50:52.054473Z","iopub.status.idle":"2024-05-18T23:50:52.240134Z","shell.execute_reply":"2024-05-18T23:50:52.239565Z","shell.execute_reply.started":"2024-05-18T23:50:52.054667Z"},"id":"sR3wMZh8S8qN","language":"python","outputId":"f01b9fe2-507d-4237-8378-d9cca9be4cac","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0308d811a96f4e61b752d86f39bb0c6a","version_major":2,"version_minor":0},"text/plain":"Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n        num_rows: 67349\n    })\n    validation: Dataset({\n        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n        num_rows: 1821\n    })\n})"},"execution_count":138,"metadata":{},"output_type":"execute_result"}],"source":"# tokenize training and validation datasets\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\ntokenized_dataset"},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T23:50:52.241358Z","iopub.status.busy":"2024-05-18T23:50:52.241032Z","iopub.status.idle":"2024-05-18T23:50:52.252186Z","shell.execute_reply":"2024-05-18T23:50:52.251693Z","shell.execute_reply.started":"2024-05-18T23:50:52.241339Z"},"id":"_sx23oGyS-7t","language":"python","trusted":true},"outputs":[],"source":"# create data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)"},{"attachments":{},"cell_type":"markdown","metadata":{"id":"t3ja7mzQWFSP"},"source":"# Utiliy Functions for Model Evaluation"},{"cell_type":"code","execution_count":140,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T23:50:52.253950Z","iopub.status.busy":"2024-05-18T23:50:52.252856Z","iopub.status.idle":"2024-05-18T23:50:52.469699Z","shell.execute_reply":"2024-05-18T23:50:52.468193Z","shell.execute_reply.started":"2024-05-18T23:50:52.253930Z"},"id":"FVWbfqUOTDgd","language":"python","trusted":true},"outputs":[{"ename":"ImportError","evalue":"To be able to use evaluate-metric/accuracy, you need to install the following dependencies['scikit-learn'] using 'pip install sklearn' for instance'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[140], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import accuracy evaluation metric\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/evaluate/loading.py:748\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    747\u001b[0m download_mode \u001b[38;5;241m=\u001b[39m DownloadMode(download_mode \u001b[38;5;129;01mor\u001b[39;00m DownloadMode\u001b[38;5;241m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[0;32m--> 748\u001b[0m evaluation_module \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m evaluation_cls \u001b[38;5;241m=\u001b[39m import_main_class(evaluation_module\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[1;32m    752\u001b[0m evaluation_instance \u001b[38;5;241m=\u001b[39m evaluation_cls(\n\u001b[1;32m    753\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[1;32m    754\u001b[0m     process_id\u001b[38;5;241m=\u001b[39mprocess_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs,\n\u001b[1;32m    761\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/evaluate/loading.py:680\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (\u001b[38;5;167;01mConnectionError\u001b[39;00m, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m)):\n\u001b[0;32m--> 680\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    682\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a module script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    683\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hugging Face Hub either.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/evaluate/loading.py:639\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m current_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomparison\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeasurement\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubEvaluationModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluate-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 639\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/evaluate/loading.py:489\u001b[0m, in \u001b[0;36mHubEvaluationModuleFactory.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    488\u001b[0m imports \u001b[38;5;241m=\u001b[39m get_imports(local_path)\n\u001b[0;32m--> 489\u001b[0m local_imports \u001b[38;5;241m=\u001b[39m \u001b[43m_download_additional_modules\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_hub_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimports\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;66;03m# copy the script and the files in an importable directory\u001b[39;00m\n\u001b[1;32m    496\u001b[0m dynamic_modules_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_modules_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_modules_path \u001b[38;5;28;01melse\u001b[39;00m init_dynamic_modules()\n","File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/evaluate/loading.py:265\u001b[0m, in \u001b[0;36m_download_additional_modules\u001b[0;34m(name, base_path, imports, download_config)\u001b[0m\n\u001b[1;32m    263\u001b[0m         needs_to_be_installed\u001b[38;5;241m.\u001b[39madd((library_import_name, library_import_path))\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_to_be_installed:\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo be able to use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, you need to install the following dependencies\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[lib_name\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlib_name,\u001b[38;5;250m \u001b[39mlib_path\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mneeds_to_be_installed]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([lib_path\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlib_name,\u001b[38;5;250m \u001b[39mlib_path\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mneeds_to_be_installed])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for instance\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m local_imports\n","\u001b[0;31mImportError\u001b[0m: To be able to use evaluate-metric/accuracy, you need to install the following dependencies['scikit-learn'] using 'pip install sklearn' for instance'"]}],"source":"# import accuracy evaluation metric\naccuracy = evaluate.load(\"accuracy\")"},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:50:52.470432Z","iopub.status.idle":"2024-05-18T23:50:52.470687Z","shell.execute_reply":"2024-05-18T23:50:52.470571Z","shell.execute_reply.started":"2024-05-18T23:50:52.470560Z"},"id":"RgmOWB1tTF8N","language":"python","trusted":true},"outputs":[],"source":"# define an evaluation function to pass into trainer later\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=1)\n\n    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"},{"attachments":{},"cell_type":"markdown","metadata":{"id":"89YKx-izWITj"},"source":"# Inference with the Base Model (to setup Baseline)"},{"cell_type":"code","execution_count":203,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-19T00:14:09.845170Z","iopub.status.busy":"2024-05-19T00:14:09.844915Z","iopub.status.idle":"2024-05-19T00:14:10.346995Z","shell.execute_reply":"2024-05-19T00:14:10.346429Z","shell.execute_reply.started":"2024-05-19T00:14:09.845155Z"},"id":"j0_AokiaTIL-","language":"python","outputId":"5701201f-fc19-430f-9579-a1e8f65e64b5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Untrained model predictions:\n----------------------------\na feel-good picture in the best sense of the term . - Positive\nresourceful and ingenious entertainment . - Positive\nit 's just incredibly dull . - Positive\nthe movie 's biggest offense is its complete and utter lack of tension . - Positive\nimpresses you with its open-endedness and surprises . - Positive\nunless you are in dire need of a diesel fix , there is no real reason to see it . - Positive\n"}],"source":"# define list of examples\ntext_list = [\"a feel-good picture in the best sense of the term .\", \"resourceful and ingenious entertainment .\", \"it 's just incredibly dull .\", \"the movie 's biggest offense is its complete and utter lack of tension .\",\n             \"impresses you with its open-endedness and surprises .\", \"unless you are in dire need of a diesel fix , there is no real reason to see it .\"]\n\nprint(\"Untrained model predictions:\")\nprint(\"----------------------------\")\nfor text in text_list:\n    # tokenize text\n    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n    # compute logits\n    logits = model(inputs).logits\n    # convert logits to label\n    predictions = torch.argmax(logits)\n\n    print(text + \" - \" + id2label[predictions.tolist()])"},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wJrM1bO8WLte"},"source":"# Model Fine-tuning"},{"cell_type":"code","execution_count":204,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:14:10.348427Z","iopub.status.busy":"2024-05-19T00:14:10.348224Z","iopub.status.idle":"2024-05-19T00:14:10.352647Z","shell.execute_reply":"2024-05-19T00:14:10.352200Z","shell.execute_reply.started":"2024-05-19T00:14:10.348410Z"},"id":"aEWCGKLbTLxV","language":"python","trusted":true},"outputs":[],"source":"peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n                        r=4,\n                        lora_alpha=32,\n                        lora_dropout=0.01,\n                        target_modules = ['query'])"},{"cell_type":"code","execution_count":205,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-19T00:14:10.353539Z","iopub.status.busy":"2024-05-19T00:14:10.353300Z","iopub.status.idle":"2024-05-19T00:14:10.357912Z","shell.execute_reply":"2024-05-19T00:14:10.357343Z","shell.execute_reply.started":"2024-05-19T00:14:10.353520Z"},"id":"uEFKNTLKTPAl","language":"python","outputId":"1fcfa09c-3214-4f2b-e872-d502ee8f4401","trusted":true},"outputs":[{"data":{"text/plain":"LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='SEQ_CLS', inference_mode=False, r=4, target_modules={'query'}, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"},"execution_count":205,"metadata":{},"output_type":"execute_result"}],"source":"peft_config"},{"cell_type":"code","execution_count":206,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-19T00:14:10.358989Z","iopub.status.busy":"2024-05-19T00:14:10.358773Z","iopub.status.idle":"2024-05-19T00:14:10.386465Z","shell.execute_reply":"2024-05-19T00:14:10.385991Z","shell.execute_reply.started":"2024-05-19T00:14:10.358971Z"},"id":"yaFePuyZTQil","language":"python","outputId":"fa62eb5c-23cb-4c02-9a07-064610e2fc7e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"trainable params: 665,858 || all params: 125,313,028 || trainable%: 0.5314\n"}],"source":"model = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()"},{"cell_type":"code","execution_count":207,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:14:10.388152Z","iopub.status.busy":"2024-05-19T00:14:10.387780Z","iopub.status.idle":"2024-05-19T00:14:10.390581Z","shell.execute_reply":"2024-05-19T00:14:10.390153Z","shell.execute_reply.started":"2024-05-19T00:14:10.388134Z"},"id":"bWHSqHIITSNt","language":"python","trusted":true},"outputs":[],"source":"# hyperparameters\nlr = 1e-3\nbatch_size = 16\nnum_epochs = 5"},{"cell_type":"code","execution_count":301,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T00:51:52.693345Z","iopub.status.busy":"2024-05-19T00:51:52.693093Z","iopub.status.idle":"2024-05-19T00:51:52.698097Z","shell.execute_reply":"2024-05-19T00:51:52.697448Z","shell.execute_reply.started":"2024-05-19T00:51:52.693329Z"},"id":"9IjsJpqDTUHO","language":"python","trusted":true},"outputs":[],"source":"# define training arguments\ntraining_args = TrainingArguments(\n    output_dir= model_checkpoint + \"-lora-text-classification\",\n    learning_rate=lr,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)"},{"cell_type":"code","execution_count":302,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"execution":{"iopub.execute_input":"2024-05-19T00:51:55.208862Z","iopub.status.busy":"2024-05-19T00:51:55.208611Z","iopub.status.idle":"2024-05-19T00:52:39.977497Z","shell.execute_reply":"2024-05-19T00:52:39.976955Z","shell.execute_reply.started":"2024-05-19T00:51:55.208846Z"},"id":"RtM0djTaTWHV","language":"python","outputId":"39526430-95a8-4eed-ec6f-45e381e26313","trusted":true},"outputs":[{"data":{"text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:43, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.088165</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.065811</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.066953</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.070208</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.069775</td>\n    </tr>\n  </tbody>\n</table><p>","text/plain":"<IPython.core.display.HTML object>"},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":"/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n"},{"data":{"text/plain":"TrainOutput(global_step=25, training_loss=0.13640908241271973, metrics={'train_runtime': 44.5284, 'train_samples_per_second': 8.983, 'train_steps_per_second': 0.561, 'total_flos': 7001790706560.0, 'train_loss': 0.13640908241271973, 'epoch': 5.0})"},"execution_count":302,"metadata":{},"output_type":"execute_result"}],"source":"# Select a subset of the dataset\ntrain_subset = tokenized_dataset[\"train\"].select(range(80))\neval_subset = tokenized_dataset[\"validation\"].select(range(20))\n\n# Create trainer object\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_subset,\n    eval_dataset=eval_subset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\n# train model\ntrainer.train()"},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5Tg5iEnNWQsm"},"source":"# Inference with the Fine-tuned Model (to setup Baseline)"},{"cell_type":"code","execution_count":303,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-19T00:52:39.978721Z","iopub.status.busy":"2024-05-19T00:52:39.978477Z","iopub.status.idle":"2024-05-19T00:52:40.507677Z","shell.execute_reply":"2024-05-19T00:52:40.507055Z","shell.execute_reply.started":"2024-05-19T00:52:39.978701Z"},"id":"3i0MiZm2Vqi9","language":"python","outputId":"d951b1d7-324f-4424-891d-4355a7b61c84","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Trained model predictions:\n--------------------------\na feel-good picture in the best sense of the term . - Positive\nresourceful and ingenious entertainment . - Positive\nit 's just incredibly dull . - Negative\nthe movie 's biggest offense is its complete and utter lack of tension . - Negative\nimpresses you with its open-endedness and surprises . - Positive\nunless you are in dire need of a diesel fix , there is no real reason to see it . - Negative\n"}],"source":"#model.to('cpu')\n\nprint(\"Trained model predictions:\")\nprint(\"--------------------------\")\nfor text in text_list:\n    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cpu\")\n\n    logits = model(inputs).logits\n    predictions = torch.max(logits,1).indices\n\n    print(text + \" - \" + id2label[predictions.tolist()[0]])"},{"cell_type":"code","execution_count":null,"metadata":{"id":"hV89O5YuXwPE","language":"python","trusted":true},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"1ef09419-817e-4b95-8f8f-5339a10ae674","defaultDatabase":"database_0311a"}},"nbformat":4,"nbformat_minor":4}